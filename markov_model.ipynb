{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"A certain king had a beautiful garden, and in the garden stood a tree which bore golden apples. These apples were always counted, and about the time when they began to grow ripe it was found that ev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def fit(self, text):\n",
    "        n = self.n\n",
    "        n_gram_dict = {}\n",
    "        text = text + text[:n]\n",
    "        for i in range(len(text) - n):\n",
    "            n_gram = text[i:i+n]\n",
    "            if n_gram not in n_gram_dict:\n",
    "                n_gram_dict[n_gram] = {\n",
    "                    text[i+n]:  text.count(text[i:i+n+1]) / text.count(n_gram)\n",
    "                }\n",
    "            elif n_gram in n_gram_dict:\n",
    "                n_gram_pred_freq = {text[i+n]: text.count(text[i:i+n+1]) / text.count(n_gram)}\n",
    "                n_gram_dict[n_gram].update(n_gram_pred_freq)\n",
    "        n_gram_dict[text[:n]][text[n]] = 1\n",
    "        return n_gram_dict\n",
    "        \n",
    "    \n",
    "    def generate(self, text, length):\n",
    "        n = self.n\n",
    "        n_gram_probs = self.fit(text)\n",
    "        #generated_text = text[:n+1]\n",
    "        generated_text = text[:n]\n",
    "        for i in range(length):\n",
    "            n_plus_letter = list(n_gram_probs[generated_text[i:i+n]].keys())\n",
    "            n_plus_prob = list(n_gram_probs[generated_text[i:i+n]].values())\n",
    "            choice = np.random.choice(len(n_plus_letter), p=n_plus_prob)\n",
    "            generated_text = generated_text + n_plus_letter[choice - 1]\n",
    "        return generated_text\n",
    "        \n",
    "\n",
    "        # probabilties need to be fixed\n",
    "        # should be count of (n_gram + next letter) / (number of distinct n_grams)] / (number of next letter / total letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A certain king had about the time when stood about the time when stood about that evA certain king had about that evA certain king had about that evA certain king had about that evA certain that evA certain king had a tree which bore apples were garden, and that evA certain to grow ripe it was found about that evA certain to grow ripe it was found in king had about that evA certain to grow ripe it was founted, and in king had about that evA certain king had about that evA certain that evA certain t\n"
     ]
    }
   ],
   "source": [
    "a = MarkovModel(n=3)\n",
    "print(a.generate(corpus, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
