{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"A certain king had a beautiful garden, and in the garden stood a tree which bore golden apples. These apples were always counted, and about the time when they began to grow ripe it was found that ev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def fit(self, text):\n",
    "        n = self.n\n",
    "        n_gram_dict = {}\n",
    "        text = text + text[:n]\n",
    "        for i in range(len(text) - n):\n",
    "            n_gram = text[i:i+n]\n",
    "            if n_gram not in n_gram_dict:\n",
    "                n_gram_dict[n_gram] = {\n",
    "                    text[i+n]:  text.count(text[i:i+n+1]) / text.count(n_gram)\n",
    "                }\n",
    "            elif n_gram in n_gram_dict:\n",
    "                n_gram_pred_freq = {text[i+n]: text.count(text[i:i+n+1]) / text.count(n_gram)}\n",
    "                n_gram_dict[n_gram].update(n_gram_pred_freq)\n",
    "        n_gram_dict[text[:n]][text[n]] = 1\n",
    "        return n_gram_dict\n",
    "        \n",
    "    \n",
    "    def generate(self, text, length):\n",
    "        n = self.n\n",
    "        n_gram_probs = self.fit(text)\n",
    "        #generated_text = text[:n+1]\n",
    "        generated_text = text[:n]\n",
    "        for i in range(length):\n",
    "            n_plus_letter = list(n_gram_probs[generated_text[i:i+n]].keys())\n",
    "            n_plus_prob = list(n_gram_probs[generated_text[i:i+n]].values())\n",
    "            choice = np.random.choice(len(n_plus_letter), p=n_plus_prob)\n",
    "            generated_text = generated_text + n_plus_letter[choice - 1]\n",
    "        return generated_text\n",
    "        \n",
    "\n",
    "        # probabilties need to be fixed\n",
    "        # should be count of (n_gram + next letter) / (number of distinct n_grams)] / (number of next letter / total letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A certain to grow ripe it was found that evA certain to grow ripe it was found a tree which bore golden, and in to grow ripe it was founted, and in king had about that evA certain king had a tree when to grow ripe it was found that evA certain to grow ripe it was founted, and about that evA certain to grow ripe it was founted, and in to grow ripe it was found in to grow ripe it was founted, and in king had about that evA certain king had about that evA certain to grow ripe it was founted, and about\n"
     ]
    }
   ],
   "source": [
    "a = MarkovModel(n=3)\n",
    "print(a.generate(corpus, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_2 = \"Hi! My name is Nao, and I am a time being. Do you know what a time being is? Well, if you give me a moment, I will tell you. A time being is someone who lives in time, and that means you, and me, and every one of us who is, or was, or ever will be. As for me, right now I am sitting in a French maid café in Akiba Electricity Town, listening to a sad chanson that is playing sometime in your past, which is also my present, writing this and wondering about you, somewhere in my future. And if you’re reading this, then maybe by now you’re wondering about me, too.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! My now who listening. Do you’re is, or was, or every one of us what me a French maid chanson this playing. Do you’re reading. Do you’re reading. Do your past, I am sitting. Do you know who is, that me, right now what me is playing. Do you’re reading. Do you, and that a momeone wondering. Do you. As for ever will be. And that a sad chanson time, too.Hi! My name a sad chans your past, I am a time, and wondering. Do your past, which maid chanson time a sad café in you. A time, then maid chanson th\n"
     ]
    }
   ],
   "source": [
    "a = MarkovModel(n=3)\n",
    "print(a.generate(corpus_2, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
